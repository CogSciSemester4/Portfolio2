---
title: "w4"
author: "Elisabet Vick"
date: "1/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

pacman::p_load(tidyverse, brms, bayesplot, viridis, ggplot2, bayestestR, rethinking, dplyr, cmdstanr, ggdag)
d <- read.csv("Ass2.csv")
```

Q1.1) Does schizophrenia involve altercentric intrusion?
(1)Define model and priors.
```{r}
#scaled Altercentric Intrusion modelled by diagnosis
d$A <- scale(d$AltercentricIntrusion) #scaling around 0
d$Diagnosis <- as.factor(d$Diagnosis)

d <- d %>% 
  mutate(Type = ifelse(Diagnosis == 1, 1, 2))
d$Type <- as.factor(d$Type)

f1 <- bf(A ~ 0 + Type)

#Get prior
get_prior(
  f1,
  d,
  family=gaussian
)

#Defining the priors. Setting conservative priors
p1 <- c(
  #brms::prior(normal(0, 0.1), class = Intercept), #not needed as we have to seperate intercepts (control v. schizophrenic patients)
  brms::prior(normal(0, 0.5), class = sigma), #Error when we predict the data points from the mean. Expected sd of the error. 
  brms::prior(normal(0, 1), class = b, coef = Type1),
  brms::prior(normal(0, 1), class = b, coef = Type2) 
)

```

(2)Test the implications of your priors (prior predictive checks) and if needed adjust them.
```{r}
#model prior to any checking
m1_prior <- brm(
  formula = f1,
  data = d,
  family = gaussian,
  prior = p1,
  sample_prior = "only",
  #file = "m1_prior"
  backend = "cmdstanr"
)

#Prior-predictive check
prior_check <- pp_check(m1_prior, nsamples = 100)

#Fitting the model
m1 <- brm(
  formula = f1,
  data = d,
  family = gaussian,
  prior = p1,
  sample_prior = T,
  #file = "m1"
  backend = "cmdstanr"
)
```

(3)Run the model.
(4)Test the quality of the fitted model (posterior predictive checks, prior-posterior updates). 
```{r}
#Posterior-predictive check
post_check <- pp_check(m1, nsamples = 100)
prior_check
post_check

#Posterior learning: Has the model learned from the data?
post_sample <- posterior_samples(m1)

#Plotting priors against posteriors
#Sigma
ggplot(post_sample) +
  theme_classic() +
  geom_density(aes(prior_sigma), fill = "red", alpha=0.3) +
  geom_density(aes(sigma), fill = "blue", alpha=0.5)

#Beta 1 (schizophrenic patients)
ggplot(post_sample) +
  theme_classic() +
  geom_density(aes(prior_b_Type1), fill = "red", alpha=0.3) +
  geom_density(aes(b_Type1), fill = "blue", alpha=0.5)

#Beta 2 (control)
ggplot(post_sample) +
  theme_classic() +
  geom_density(aes(prior_b_Type2), fill = "red", alpha=0.3) +
  geom_density(aes(b_Type2), fill = "blue", alpha=0.5)
```

(5)Assess the evidence in favor of an increased altercentric intrusion in schizophrenia.
```{r}
#Plotting the model
plot(conditional_effects(m1), points = TRUE)
#Fitted
plot(conditional_effects(m1), spaghetti = TRUE, nsamples = 100, method = "fitted",  points = TRUE)
#Predicted
plot(conditional_effects(m1), spaghetti = TRUE, nsamples = 100, method = "predicted",  points = TRUE)
```


```{r}
##contrast of the two diagnosis
pacman::p_load(tidybayes)
postsamp <- posterior_samples(m1) %>% 
  mutate(diff = b_Type1 - b_Type2 ) %>% 
  gather(key, value, -`lp__`) %>% 
  group_by(key) %>% 
  mean_qi(value, .width = .89)
postsamp
```

(6)Report the model and the results, including plots.

Q1.2) Is altercentric intrusion related to specific symptoms *in the patients*? Identify which of the symptoms could be relevant (given their description above). Should you include more than one symptom? Build models, priors, predictive checks. Assess the evidence and report models and results, including plots. Discuss whether the results make sense.
```{r}
#subset and scale
d_sub <- subset(d, Diagnosis == 1) #create df with only schizophrenic patients
d_sub$Ap <- scale(d_sub$Apathy)
d_sub$M <- scale(d_sub$MindReading)
d_sub$V <- scale(d_sub$VoiceHearing)
d_sub$A <- scale(d_sub$AltercentricIntrusion)
```

```{r}
####Creating three different univariate models
###VOICE HEARING
f_V <- bf(A ~ 1 + V )
m_V_prior <- brm(
  formula = f_V,
  data = d_sub,
  family = gaussian,
  prior =  c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept), 
           prior (normal (0, 1), class = b, coef = V)),
  sample_prior = "only",
 # file = "m_V_prior", 
  backend = "cmdstanr"
)

#Fitting the model
m_V <- brm(
  formula = f_V,
  data = d_sub,
  family = gaussian,
  prior = c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept),
           prior (normal (0, 1), class = b, coef = V)),
  sample_prior = T,
#  file = "m_V", 
  backend = "cmdstanr")

#Prior predictive check
pp_check(m_V_prior, nsamples = 100)

#Posterior predictive check
pp_check(m_V, nsamples = 100)
print(m_V)

#Hypothesis testing
hypothesis(m_V, "V > 0")
```

```{r}
##APATHY
f_Ap <- bf(A ~ 1 + Ap )
get_prior(f_Ap, data = d_sub, family = gaussian)

m_Ap_prior <- brm(
  formula = f_Ap,
  data = d_sub,
  family = gaussian,
  prior =  c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept), 
           prior (normal (0, 1), class = b, coef = Ap)),
  sample_prior = "only",
 # file = "m_V_prior", 
  backend = "cmdstanr"
)

#Fitting the model
m_Ap <- brm(
  formula = f_Ap,
  data = d_sub,
  family = gaussian,
  prior = c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept),
           prior (normal (0, 1), class = b, coef = Ap)),
  sample_prior = T,
#  file = "m_V", 
  backend = "cmdstanr")


#Prior predictive check
pp_check(m_Ap_prior, nsamples = 100)

#Posterior predictive check
pp_check(m_Ap, nsamples = 100)
print(m_Ap)

#Hypothesis testing
hypothesis(m_Ap, "Ap < 0")
```

```{r}
###MINDREADING
f_M <- bf(A ~ 1 + M )
m_M_prior <- brm(
  formula = f_M,
  data = d_sub,
  family = gaussian,
  prior =  c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept), 
           prior (normal (0, 1), class = b, coef = M)),
  sample_prior = "only",
 # file = "m_V_prior", 
  backend = "cmdstanr")

#Fitting the model
m_M <- brm(
  formula = f_M,
  data = d_sub,
  family = gaussian,
  prior = c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept),
           prior (normal (0, 1), class = b, coef = M)),
  sample_prior = T,
#  file = "m_V", 
  backend = "cmdstanr")

#Prior predictive check
pp_check(m_M_prior, nsamples = 100)

#Posterior predictive check
pp_check(m_M, nsamples = 100)
print(m_M)

#Hypothesis testing
hypothesis(m_M, "M > 0")
```

## Second part

Q2.1) However, we know that the diagnosis is based on symptom assessment: if the overall sum of symptoms is severe enough, the participant gets a diagnosis. In other words, by selecting the patients, and including the symptoms in the model we might have inadvertently introduced an issue in our inference. Do try to draw a causal graph (Directed Acyclical Graph, DAG) of the variables and compare it with the types of causal graphs presented in the slides. Discuss which biases you might have introduced.

```{r}
#Creating the DAG
dag2_coords <- tibble(
  name = c("V", "M", "AI", "A", "D"),
  x = c(1, 3, 2, 2, 2),
  y = c(4, 4, 1, 3, 2))

dagify(M ~ V,
       AI ~ M + V + D,
       D ~ A + V + M,
       coords = dag2_coords) %>%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(aes(color = name == "D"),
                 alpha = 1/2, size = 6.5, show.legend = F) +
  geom_dag_text(color = "black") +
  geom_dag_edges() +
  scale_color_manual(values = c("steelblue", "orange")) +
  scale_x_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(.1, .1))

```

Q2.2.) Redesign your analysis following the graph and report how the results change

```{r}
#We want to run the models on the full dataset
#Scale and rename
df1 <- df
df1$Ap <- scale(df1$Apathy)
df1$M <- scale(df1$MindReading)
df1$V <- scale(df1$VoiceHearing)
df1$A <- scale(df1$AltercentricIntrusion)

```

```{r}
###MIND READING
m1_M_prior <- brm(
  formula = f_M,
  data = df1,
  family = gaussian,
  prior =  c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept), 
           prior (normal (0, 1), class = b, coef = M)),
  sample_prior = "only",
 # file = "m_V_prior", 
  backend = "cmdstanr"
)

#Fitting the model
m1_M <- brm(
  formula = f_M,
  data = df1,
  family = gaussian,
  prior = c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept),
           prior (normal (0, 1), class = b, coef = M)),
  sample_prior = T,
#  file = "m_V",
  backend = "cmdstanr")

#Prior predictive check
pp_check(m1_M_prior, nsamples = 100)

#Posterior predictive check
pp_check(m1_M, nsamples = 100)
print(m1_M)

#Hypothesis testing
hypothesis(m1_M, "M < 0")

```
```{r}
###VOICE HEARING
m1_V_prior <- brm(
  formula = f_V,
  data = df1,
  family = gaussian,
  prior =  c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept), 
           prior (normal (0, 1), class = b, coef = V)),
  sample_prior = "only",
 # file = "m_V_prior", 
  backend = "cmdstanr"
)

#Fitting the model
m1_V <- brm(
  formula = f_V,
  data = df1,
  family = gaussian,
  prior = c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept),
           prior (normal (0, 1), class = b, coef = V)),
  sample_prior = T,
#  file = "m_V", 
  backend = "cmdstanr")

#Prior predictive check
pp_check(m1_V_prior, nsamples = 100)

#Posterior predictive check
pp_check(m1_V, nsamples = 100)
print(m1_V)

#Hypothesis testing
hypothesis(m1_V, "V < 0")
```

```{r}
###Apathy
m1_Ap_prior <- brm(
  formula = f_Ap,
  data = df1,
  family = gaussian,
  prior =  c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept), 
           prior (normal (0, 1), class = b, coef = Ap)),
  sample_prior = "only",
 # file = "m_V_prior", 
  backend = "cmdstanr"
)

#Fitting the model
m1_Ap <- brm(
  formula = f_Ap,
  data = df1,
  family = gaussian,
  prior = c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept),
           prior (normal (0, 1), class = b, coef = Ap)),
  sample_prior = T,
#  file = "m_V", 
  backend = "cmdstanr")


#Prior predictive check
pp_check(m1_Ap_prior, nsamples = 100)

#Posterior predictive check
pp_check(m1_Ap, nsamples = 100)
print(m1_Ap)

#Hypothesis testing
hypothesis(m1_Ap, "Ap < 0")
```


```{r}
#Multivariate model
###MINDREADING + VOICE HEARING
f_MV <- bf(A ~ 1 + M + V)
m_MV_prior <- brm(
  formula = f_MV,
  data = df1,
  family = gaussian,
  prior =  c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept), 
           prior (normal (0, 1), class = b, coef = M),
           prior (normal (0, 1), class = b, coef = V)),
  sample_prior = "only",
 # file = "m_V_prior", 
  backend = "cmdstanr"
)

#Fitting the model
m_MV <- brm(
  formula = f_MV,
  data = df1,
  family = gaussian,
  prior = c(prior( normal (0, 0.5), class = sigma),
           prior (normal (0, 0.5), class = Intercept),
           prior (normal (0, 1), class = b, coef = M),
           prior (normal (0, 1), class = b, coef = V)),
  sample_prior = T,
#  file = "m_V", 
  backend = "cmdstanr")

#prior predictive check
pp_check(m_MV_prior, nsamples = 100)

#posterior predictive check
pp_check(m_MV, nsamples = 100)
print(m_MV)
```




## Third part

These issues are very difficult to think through, and not knowing the causal mechanisms generating the data in advance makes our inferences even more unreliable. To explore these issues, I recommend using simulations. In other words, defining a "true" model, generating data from it and assessing what different analyses would lead you to infer (and therefore which biases they might introduce). You can find the code I used to simulate your data below.

Q3.1) Look through the code and identify whether the results you have match the underlying truth. Discuss what you have learned.

Q3.2) OPTIONAL: is this a general pattern? Try varying the parameters (e.g. correlation values) and assess whether the new dataset(s) leads to the same biases in your analysis.



```{r}
pacman::p_load(MASS, tidyverse, psych)

seed <- 1981 # Defining a seed so the results are always the same
n <- 300 # Defining the amount of participants

SymptomCorr <- .2 # Defining the correlation of symptoms (as they tend to co-occur)
EffectCorrRel <- .2 # Defining the correlation between relevant symptoms and effect (Some symptoms are positively correlated with the effect)
EffectCorrIrrel <- 0 # Defining the correlation between irrelevant symptoms and effect (none)

# Creating the variance-covariance matrix for the variables we want to generate (3 symptoms, 1 effect)
Sigma <- matrix(data=c(1,SymptomCorr,SymptomCorr,EffectCorrRel,
                       SymptomCorr,1,SymptomCorr,EffectCorrRel,
                       SymptomCorr,SymptomCorr,1,EffectCorrIrrel,
                       EffectCorrRel,EffectCorrRel,EffectCorrIrrel,1),
                       nrow=4,ncol=4)

## Generate data from a multivariate (mvr) normal (n) distribution
d <- mvrnorm(n = n, # number of participant
        mu = c(1.2, 1.2, 1.2, 4), # mean of each variable
        Sigma) # variance co-variance matrix

# Giving meaningful names to variables and add ID
d <- data.frame(
  VoiceHearing = d[,1], 
  MindReading =  d[,2],
  Apathy =  d[,3], 
  AltercentricIntrusion = d[,4],
  ID = seq(nrow(d)))

# Assessing whether the participant has schizophrenia (high enough sum of symptoms)
# Here we choose participants scoring above 75% percentile (the most severe ones)
d$Diagnosis <- 0
d$Diagnosis[(d$VoiceHearing + d$MindReading + d$Apathy) > 
              quantile(d$VoiceHearing + d$MindReading + d$Apathy, .75)] <- 1

## Plotting the relation between variables all participants
pairs.panels(dplyr::select(d,-Diagnosis, -ID))


## Plotting the relation between variables in schizophrenia
d1 <- d %>% subset(Diagnosis==1) %>% dplyr::select(-Diagnosis, -ID)
pairs.panels(d1)


write_csv(d, "data/Ass2.csv")
```


